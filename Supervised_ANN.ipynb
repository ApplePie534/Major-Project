{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pcuMJrlZZz7v",
        "outputId": "345cffeb-7c5e-4553-9bca-c869d8379106"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/50], Labeled Loss: 0.6995, Test Accuracy: 9.74%\n",
            "Epoch [2/50], Labeled Loss: 2.4257, Test Accuracy: 9.82%\n",
            "Epoch [3/50], Labeled Loss: 1.6666, Test Accuracy: 52.72%\n",
            "Epoch [4/50], Labeled Loss: 0.2781, Test Accuracy: 65.31%\n",
            "Epoch [5/50], Labeled Loss: 0.2863, Test Accuracy: 67.30%\n",
            "Epoch [6/50], Labeled Loss: 0.2363, Test Accuracy: 68.31%\n",
            "Epoch [7/50], Labeled Loss: 0.1447, Test Accuracy: 73.44%\n",
            "Epoch [8/50], Labeled Loss: 0.1582, Test Accuracy: 78.94%\n",
            "Epoch [9/50], Labeled Loss: 0.1214, Test Accuracy: 83.46%\n",
            "Epoch [10/50], Labeled Loss: 0.1190, Test Accuracy: 82.50%\n",
            "Epoch [11/50], Labeled Loss: 0.0828, Test Accuracy: 81.45%\n",
            "Epoch [12/50], Labeled Loss: 0.0870, Test Accuracy: 83.90%\n",
            "Epoch [13/50], Labeled Loss: 0.0672, Test Accuracy: 85.57%\n",
            "Epoch [14/50], Labeled Loss: 0.0589, Test Accuracy: 86.55%\n",
            "Epoch [15/50], Labeled Loss: 0.0443, Test Accuracy: 87.56%\n",
            "Epoch [16/50], Labeled Loss: 0.0364, Test Accuracy: 87.67%\n",
            "Epoch [17/50], Labeled Loss: 0.0362, Test Accuracy: 88.06%\n",
            "Epoch [18/50], Labeled Loss: 0.0260, Test Accuracy: 87.93%\n",
            "Epoch [19/50], Labeled Loss: 0.0209, Test Accuracy: 87.22%\n",
            "Epoch [20/50], Labeled Loss: 0.0210, Test Accuracy: 87.88%\n",
            "Epoch [21/50], Labeled Loss: 0.0152, Test Accuracy: 87.88%\n",
            "Epoch [22/50], Labeled Loss: 0.0150, Test Accuracy: 88.00%\n",
            "Epoch [23/50], Labeled Loss: 0.0135, Test Accuracy: 88.82%\n",
            "Epoch [24/50], Labeled Loss: 0.0091, Test Accuracy: 88.67%\n",
            "Epoch [25/50], Labeled Loss: 0.0090, Test Accuracy: 88.76%\n",
            "Epoch [26/50], Labeled Loss: 0.0072, Test Accuracy: 88.91%\n",
            "Epoch [27/50], Labeled Loss: 0.0045, Test Accuracy: 89.20%\n",
            "Epoch [28/50], Labeled Loss: 0.0047, Test Accuracy: 89.34%\n",
            "Epoch [29/50], Labeled Loss: 0.0051, Test Accuracy: 89.36%\n",
            "Epoch [30/50], Labeled Loss: 0.0044, Test Accuracy: 89.42%\n",
            "Epoch [31/50], Labeled Loss: 0.0035, Test Accuracy: 89.53%\n",
            "Epoch [32/50], Labeled Loss: 0.0033, Test Accuracy: 89.47%\n",
            "Epoch [33/50], Labeled Loss: 0.0024, Test Accuracy: 89.40%\n",
            "Epoch [34/50], Labeled Loss: 0.0025, Test Accuracy: 89.33%\n",
            "Epoch [35/50], Labeled Loss: 0.0027, Test Accuracy: 89.30%\n",
            "Epoch [36/50], Labeled Loss: 0.0018, Test Accuracy: 89.36%\n",
            "Epoch [37/50], Labeled Loss: 0.0016, Test Accuracy: 89.32%\n",
            "Epoch [38/50], Labeled Loss: 0.0017, Test Accuracy: 89.27%\n",
            "Epoch [39/50], Labeled Loss: 0.0015, Test Accuracy: 89.13%\n",
            "Epoch [40/50], Labeled Loss: 0.0013, Test Accuracy: 89.13%\n",
            "Epoch [41/50], Labeled Loss: 0.0012, Test Accuracy: 89.18%\n",
            "Epoch [42/50], Labeled Loss: 0.0012, Test Accuracy: 89.21%\n",
            "Epoch [43/50], Labeled Loss: 0.0009, Test Accuracy: 89.19%\n",
            "Epoch [44/50], Labeled Loss: 0.0011, Test Accuracy: 89.15%\n",
            "Epoch [45/50], Labeled Loss: 0.0011, Test Accuracy: 89.27%\n",
            "Epoch [46/50], Labeled Loss: 0.0009, Test Accuracy: 89.18%\n",
            "Epoch [47/50], Labeled Loss: 0.0007, Test Accuracy: 89.23%\n",
            "Epoch [48/50], Labeled Loss: 0.0008, Test Accuracy: 89.27%\n",
            "Epoch [49/50], Labeled Loss: 0.0005, Test Accuracy: 89.34%\n",
            "Epoch [50/50], Labeled Loss: 0.0011, Test Accuracy: 89.35%\n",
            "Accuracy on test set: 89 %\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision.transforms import transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "class PseudoLabelNet(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super(PseudoLabelNet, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.sigmoid(x)\n",
        "        return x\n",
        "\n",
        "def train_supervised(model, labeled_loader, test_loader, device, epochs):\n",
        "    optimizer = optim.SGD(model.parameters(), lr=1.5, momentum=0.9)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "\n",
        "        labeled_loss = 0.0\n",
        "\n",
        "        # Train on labeled data\n",
        "        for i, (x, y) in enumerate(labeled_loader):\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output = model(x)\n",
        "            y_onehot = torch.zeros_like(output).scatter_(1, y.unsqueeze(1), 1)\n",
        "            labeled_loss += nn.BCELoss()(output, y_onehot)\n",
        "        labeled_loss /= len(labeled_loader)\n",
        "\n",
        "        loss = labeled_loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Evaluate on test set\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for images, labels in test_loader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                outputs = model(images)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "        test_accuracy = 100 * correct / total\n",
        "\n",
        "        print(f'Epoch [{epoch+1}/{epochs}], Labeled Loss: {labeled_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%')\n",
        "\n",
        "def main():\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # Load MNIST dataset\n",
        "    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
        "    train_set = MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "    test_set = MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "    # Split dataset into labeled and unlabeled\n",
        "    labeled_indices = torch.randperm(len(train_set))[:600]\n",
        "    labeled_dataset = torch.utils.data.Subset(train_set, labeled_indices)\n",
        "\n",
        "    # Create dataloaders\n",
        "    labeled_loader = DataLoader(labeled_dataset, batch_size=32, shuffle=True)\n",
        "    test_loader = DataLoader(test_set, batch_size=1000, shuffle=False)\n",
        "\n",
        "    # Create model and train\n",
        "    model = PseudoLabelNet(28*28, 5000, 10).to(device)\n",
        "\n",
        "    train_supervised(model, labeled_loader, test_loader, device, 50)\n",
        "\n",
        "    # Evaluate on test set\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print('Accuracy on test set: %d %%' % (100 * correct / total))\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ]
}