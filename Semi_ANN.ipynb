{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1U8WHxaWBF1j"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision.transforms import transforms\n",
        "from torch.utils.data import DataLoader, Dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class PseudoLabelDataset(Dataset):\n",
        "    def __init__(self, dataset, device):\n",
        "        self.dataset = dataset\n",
        "        self.device = device\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img, _ = self.dataset[index]\n",
        "        return img.to(self.device)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)"
      ],
      "metadata": {
        "id": "r4reHk2-RCVK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class PseudoLabelNet(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super(PseudoLabelNet, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.sigmoid(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "jm0q_HL9CrG2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, labeled_loader, unlabeled_loader, test_loader, device, epochs, alpha_schedule):\n",
        "    optimizer = optim.SGD(model.parameters(), lr=1.5, momentum=0.9)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "\n",
        "        labeled_loss = 0.0\n",
        "        unlabeled_loss = 0.0\n",
        "\n",
        "        # Train on labeled data\n",
        "        for i, (x, y) in enumerate(labeled_loader):\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output = model(x)\n",
        "            y_onehot = torch.zeros_like(output).scatter_(1, y.unsqueeze(1), 1)\n",
        "            labeled_loss += nn.BCELoss()(output, y_onehot)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        labeled_loss /= len(labeled_loader)\n",
        "\n",
        "        # Train on unlabeled data with Pseudo-Labels\n",
        "        alpha = alpha_schedule(epoch)\n",
        "        for i, x in enumerate(unlabeled_loader):\n",
        "            x = x.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output = model(x)\n",
        "            pseudo_labels = (output.max(1)[1].float().unsqueeze(1) == torch.arange(10).unsqueeze(0).to(device)).float()\n",
        "            unlabeled_loss += alpha * nn.BCELoss()(output, pseudo_labels)\n",
        "        unlabeled_loss /= len(unlabeled_loader)\n",
        "\n",
        "        loss = labeled_loss + unlabeled_loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Evaluate on test set\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for images, labels in test_loader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                outputs = model(images)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "        test_accuracy = 100 * correct / total\n",
        "\n",
        "        print(f'Epoch [{epoch+1}/{epochs}], Labeled Loss: {labeled_loss:.4f}, Unlabeled Loss: {unlabeled_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%')\n"
      ],
      "metadata": {
        "id": "f46ZFGlxDK5K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(device)\n",
        "\n",
        "    # Load MNIST dataset\n",
        "    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
        "    train_set = MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "    test_set = MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "    # Split dataset into labeled and unlabeled\n",
        "    labeled_indices = torch.randperm(len(train_set))[:600]\n",
        "    unlabeled_indices = torch.randperm(len(train_set))[600:]\n",
        "    labeled_dataset = torch.utils.data.Subset(train_set, labeled_indices)\n",
        "    unlabeled_dataset = torch.utils.data.Subset(train_set, unlabeled_indices)\n",
        "\n",
        "    # Create dataloaders\n",
        "    labeled_loader = DataLoader(labeled_dataset, batch_size=32, shuffle=True)\n",
        "    unlabeled_loader = DataLoader(PseudoLabelDataset(unlabeled_dataset, device), batch_size=256, shuffle=True)\n",
        "    test_loader = DataLoader(test_set, batch_size=1000, shuffle=False)\n",
        "\n",
        "    # Create model and train\n",
        "    model = PseudoLabelNet(28*28, 5000, 10).to(device)\n",
        "\n",
        "    T1 = 10\n",
        "    T2 = 40\n",
        "\n",
        "    def alpha_schedule(epoch):\n",
        "        if epoch < T1:\n",
        "            return 0\n",
        "        elif epoch < T2:\n",
        "            return ((epoch - T1) / (T2 - T1)) * 3\n",
        "        else:\n",
        "            return 3\n",
        "\n",
        "    train(model, labeled_loader, unlabeled_loader,test_loader, device, 50, alpha_schedule)\n",
        "\n",
        "    # Evaluate on test set\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print('Accuracy on test set: %d %%' % (100 * correct / total))\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kt4aRWjPDuJe",
        "outputId": "97f620df-aa7a-4fa3-db72-f9d68f7173c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n",
            "Epoch [1/50], Labeled Loss: 0.7296, Unlabeled Loss: 0.0000, Test Accuracy: 9.74%\n",
            "Epoch [2/50], Labeled Loss: 2.5380, Unlabeled Loss: 0.0000, Test Accuracy: 10.49%\n",
            "Epoch [3/50], Labeled Loss: 2.0290, Unlabeled Loss: 0.0000, Test Accuracy: 39.19%\n",
            "Epoch [4/50], Labeled Loss: 0.3259, Unlabeled Loss: 0.0000, Test Accuracy: 61.99%\n",
            "Epoch [5/50], Labeled Loss: 0.2867, Unlabeled Loss: 0.0000, Test Accuracy: 62.78%\n",
            "Epoch [6/50], Labeled Loss: 0.2500, Unlabeled Loss: 0.0000, Test Accuracy: 63.66%\n",
            "Epoch [7/50], Labeled Loss: 0.1553, Unlabeled Loss: 0.0000, Test Accuracy: 69.16%\n",
            "Epoch [8/50], Labeled Loss: 0.1577, Unlabeled Loss: 0.0000, Test Accuracy: 73.73%\n",
            "Epoch [9/50], Labeled Loss: 0.1221, Unlabeled Loss: 0.0000, Test Accuracy: 79.78%\n",
            "Epoch [10/50], Labeled Loss: 0.1134, Unlabeled Loss: 0.0000, Test Accuracy: 79.74%\n",
            "Epoch [11/50], Labeled Loss: 0.0986, Unlabeled Loss: 0.0000, Test Accuracy: 77.39%\n",
            "Epoch [12/50], Labeled Loss: 0.0872, Unlabeled Loss: 0.0058, Test Accuracy: 78.61%\n",
            "Epoch [13/50], Labeled Loss: 0.0742, Unlabeled Loss: 0.0103, Test Accuracy: 81.19%\n",
            "Epoch [14/50], Labeled Loss: 0.0585, Unlabeled Loss: 0.0149, Test Accuracy: 86.32%\n",
            "Epoch [15/50], Labeled Loss: 0.0411, Unlabeled Loss: 0.0172, Test Accuracy: 86.16%\n",
            "Epoch [16/50], Labeled Loss: 0.0443, Unlabeled Loss: 0.0229, Test Accuracy: 87.56%\n",
            "Epoch [17/50], Labeled Loss: 0.0293, Unlabeled Loss: 0.0233, Test Accuracy: 87.42%\n",
            "Epoch [18/50], Labeled Loss: 0.0218, Unlabeled Loss: 0.0255, Test Accuracy: 86.26%\n",
            "Epoch [19/50], Labeled Loss: 0.0229, Unlabeled Loss: 0.0291, Test Accuracy: 86.54%\n",
            "Epoch [20/50], Labeled Loss: 0.0172, Unlabeled Loss: 0.0317, Test Accuracy: 87.41%\n",
            "Epoch [21/50], Labeled Loss: 0.0150, Unlabeled Loss: 0.0327, Test Accuracy: 88.07%\n",
            "Epoch [22/50], Labeled Loss: 0.0132, Unlabeled Loss: 0.0326, Test Accuracy: 88.64%\n",
            "Epoch [23/50], Labeled Loss: 0.0107, Unlabeled Loss: 0.0335, Test Accuracy: 89.33%\n",
            "Epoch [24/50], Labeled Loss: 0.0091, Unlabeled Loss: 0.0344, Test Accuracy: 89.45%\n",
            "Epoch [25/50], Labeled Loss: 0.0081, Unlabeled Loss: 0.0358, Test Accuracy: 89.57%\n",
            "Epoch [26/50], Labeled Loss: 0.0071, Unlabeled Loss: 0.0365, Test Accuracy: 89.64%\n",
            "Epoch [27/50], Labeled Loss: 0.0059, Unlabeled Loss: 0.0365, Test Accuracy: 89.66%\n",
            "Epoch [28/50], Labeled Loss: 0.0049, Unlabeled Loss: 0.0380, Test Accuracy: 89.93%\n",
            "Epoch [29/50], Labeled Loss: 0.0042, Unlabeled Loss: 0.0379, Test Accuracy: 90.16%\n",
            "Epoch [30/50], Labeled Loss: 0.0031, Unlabeled Loss: 0.0380, Test Accuracy: 90.08%\n",
            "Epoch [31/50], Labeled Loss: 0.0035, Unlabeled Loss: 0.0388, Test Accuracy: 90.04%\n",
            "Epoch [32/50], Labeled Loss: 0.0024, Unlabeled Loss: 0.0395, Test Accuracy: 90.01%\n",
            "Epoch [33/50], Labeled Loss: 0.0025, Unlabeled Loss: 0.0399, Test Accuracy: 90.16%\n",
            "Epoch [34/50], Labeled Loss: 0.0022, Unlabeled Loss: 0.0400, Test Accuracy: 90.21%\n",
            "Epoch [35/50], Labeled Loss: 0.0025, Unlabeled Loss: 0.0402, Test Accuracy: 90.30%\n",
            "Epoch [36/50], Labeled Loss: 0.0014, Unlabeled Loss: 0.0406, Test Accuracy: 90.64%\n",
            "Epoch [37/50], Labeled Loss: 0.0014, Unlabeled Loss: 0.0405, Test Accuracy: 90.82%\n",
            "Epoch [38/50], Labeled Loss: 0.0014, Unlabeled Loss: 0.0412, Test Accuracy: 90.93%\n",
            "Epoch [39/50], Labeled Loss: 0.0016, Unlabeled Loss: 0.0411, Test Accuracy: 90.99%\n",
            "Epoch [40/50], Labeled Loss: 0.0012, Unlabeled Loss: 0.0417, Test Accuracy: 91.01%\n",
            "Epoch [41/50], Labeled Loss: 0.0017, Unlabeled Loss: 0.0423, Test Accuracy: 90.89%\n",
            "Epoch [42/50], Labeled Loss: 0.0010, Unlabeled Loss: 0.0407, Test Accuracy: 90.98%\n",
            "Epoch [43/50], Labeled Loss: 0.0012, Unlabeled Loss: 0.0389, Test Accuracy: 91.21%\n",
            "Epoch [44/50], Labeled Loss: 0.0008, Unlabeled Loss: 0.0382, Test Accuracy: 91.29%\n",
            "Epoch [45/50], Labeled Loss: 0.0011, Unlabeled Loss: 0.0377, Test Accuracy: 91.38%\n",
            "Epoch [46/50], Labeled Loss: 0.0013, Unlabeled Loss: 0.0365, Test Accuracy: 91.38%\n",
            "Epoch [47/50], Labeled Loss: 0.0009, Unlabeled Loss: 0.0363, Test Accuracy: 91.47%\n",
            "Epoch [48/50], Labeled Loss: 0.0008, Unlabeled Loss: 0.0345, Test Accuracy: 91.49%\n",
            "Epoch [49/50], Labeled Loss: 0.0007, Unlabeled Loss: 0.0341, Test Accuracy: 91.47%\n",
            "Epoch [50/50], Labeled Loss: 0.0007, Unlabeled Loss: 0.0335, Test Accuracy: 91.51%\n",
            "Accuracy on test set: 91 %\n"
          ]
        }
      ]
    }
  ]
}